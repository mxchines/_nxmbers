[
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "jmespath",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jmespath",
        "description": "jmespath",
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "jmespath",
        "description": "jmespath",
        "isExtraImport": true,
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "getpass",
        "importPath": "getpass",
        "description": "getpass",
        "isExtraImport": true,
        "detail": "getpass",
        "documentation": {}
    },
    {
        "label": "OptionParser",
        "importPath": "optparse",
        "description": "optparse",
        "isExtraImport": true,
        "detail": "optparse",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "print_",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "CockroachDatabase",
        "importPath": "playhouse.cockroachdb",
        "description": "playhouse.cockroachdb",
        "isExtraImport": true,
        "detail": "playhouse.cockroachdb",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "playhouse.reflection",
        "description": "playhouse.reflection",
        "isExtraImport": true,
        "detail": "playhouse.reflection",
        "documentation": {}
    },
    {
        "label": "rpy2.robjects",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rpy2.robjects",
        "description": "rpy2.robjects",
        "detail": "rpy2.robjects",
        "documentation": {}
    },
    {
        "label": "pandas2ri",
        "importPath": "rpy2.robjects",
        "description": "rpy2.robjects",
        "isExtraImport": true,
        "detail": "rpy2.robjects",
        "documentation": {}
    },
    {
        "label": "importr",
        "importPath": "rpy2.robjects.packages",
        "description": "rpy2.robjects.packages",
        "isExtraImport": true,
        "detail": "rpy2.robjects.packages",
        "documentation": {}
    },
    {
        "label": "localconverter",
        "importPath": "rpy2.robjects.conversion",
        "description": "rpy2.robjects.conversion",
        "isExtraImport": true,
        "detail": "rpy2.robjects.conversion",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "importPath": "path_utility",
        "description": "path_utility",
        "isExtraImport": true,
        "detail": "path_utility",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "importPath": "path_utility",
        "description": "path_utility",
        "isExtraImport": true,
        "detail": "path_utility",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "importPath": "path_utility",
        "description": "path_utility",
        "isExtraImport": true,
        "detail": "path_utility",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "importPath": "path_utility",
        "description": "path_utility",
        "isExtraImport": true,
        "detail": "path_utility",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "TimeSeries",
        "importPath": "alpha_vantage.timeseries",
        "description": "alpha_vantage.timeseries",
        "isExtraImport": true,
        "detail": "alpha_vantage.timeseries",
        "documentation": {}
    },
    {
        "label": "gql",
        "importPath": "gql",
        "description": "gql",
        "isExtraImport": true,
        "detail": "gql",
        "documentation": {}
    },
    {
        "label": "Client",
        "importPath": "gql",
        "description": "gql",
        "isExtraImport": true,
        "detail": "gql",
        "documentation": {}
    },
    {
        "label": "RequestsHTTPTransport",
        "importPath": "gql.transport.requests",
        "description": "gql.transport.requests",
        "isExtraImport": true,
        "detail": "gql.transport.requests",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "config",
        "description": "config",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "psycopg2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psycopg2",
        "description": "psycopg2",
        "detail": "psycopg2",
        "documentation": {}
    },
    {
        "label": "sql",
        "importPath": "psycopg2",
        "description": "psycopg2",
        "isExtraImport": true,
        "detail": "psycopg2",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "data_ingestion.data_fetcher",
        "description": "data_ingestion.data_fetcher",
        "isExtraImport": true,
        "detail": "data_ingestion.data_fetcher",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "data_ingestion.data_fetcher",
        "description": "data_ingestion.data_fetcher",
        "isExtraImport": true,
        "detail": "data_ingestion.data_fetcher",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "data_ingestion.data_combiner",
        "description": "data_ingestion.data_combiner",
        "isExtraImport": true,
        "detail": "data_ingestion.data_combiner",
        "documentation": {}
    },
    {
        "label": "clean_data",
        "importPath": "data_cleaning.data_cleaner",
        "description": "data_cleaning.data_cleaner",
        "isExtraImport": true,
        "detail": "data_cleaning.data_cleaner",
        "documentation": {}
    },
    {
        "label": "run_r_models",
        "importPath": "prediction_model.r_model_executor",
        "description": "prediction_model.r_model_executor",
        "isExtraImport": true,
        "detail": "prediction_model.r_model_executor",
        "documentation": {}
    },
    {
        "label": "save_results",
        "importPath": "results_storage.results_saver",
        "description": "results_storage.results_saver",
        "isExtraImport": true,
        "detail": "results_storage.results_saver",
        "documentation": {}
    },
    {
        "label": "upload_to_rds",
        "importPath": "data_storage.rds_uploader",
        "description": "data_storage.rds_uploader",
        "isExtraImport": true,
        "detail": "data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "abacus.bin.jp",
        "description": "abacus.bin.jp",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()",
        "detail": "abacus.bin.jp",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "kind": 6,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "class BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "UnknownField",
        "kind": 6,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "class UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}\nDATABASE_MAP = dict((value, key)",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "make_introspector",
        "kind": 2,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "def make_introspector(database_type, database_name, **kwargs):\n    if database_type not in DATABASE_MAP:\n        err('Unrecognized database, must be one of: %s' %\n            ', '.join(DATABASE_MAP.keys()))\n        sys.exit(1)\n    schema = kwargs.pop('schema', None)\n    DatabaseClass = DATABASE_MAP[database_type]\n    db = DatabaseClass(database_name, **kwargs)\n    return Introspector.from_database(db, schema=schema)\ndef print_models(introspector, tables=None, preserve_order=False,",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "print_models",
        "kind": 2,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "def print_models(introspector, tables=None, preserve_order=False,\n                 include_views=False, ignore_unknown=False, snake_case=True):\n    database = introspector.introspect(table_names=tables,\n                                       include_views=include_views,\n                                       snake_case=snake_case)\n    db_kwargs = introspector.get_database_kwargs()\n    header = HEADER % (\n        introspector.get_additional_imports(),\n        introspector.get_database_class().__name__,\n        introspector.get_database_name(),",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "print_header",
        "kind": 2,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "def print_header(cmd_line, introspector):\n    timestamp = datetime.datetime.now()\n    print_('# Code generated by:')\n    print_('# python -m pwiz %s' % cmd_line)\n    print_('# Date: %s' % timestamp.strftime('%B %d, %Y %I:%M%p'))\n    print_('# Database: %s' % introspector.get_database_name())\n    print_('# Peewee version: %s' % peewee_version)\n    print_('')\ndef err(msg):\n    sys.stderr.write('\\033[91m%s\\033[0m\\n' % msg)",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "err",
        "kind": 2,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "def err(msg):\n    sys.stderr.write('\\033[91m%s\\033[0m\\n' % msg)\n    sys.stderr.flush()\ndef get_option_parser():\n    parser = OptionParser(usage='usage: %prog [options] database_name')\n    ao = parser.add_option\n    ao('-H', '--host', dest='host')\n    ao('-p', '--port', dest='port', type='int')\n    ao('-u', '--user', dest='user')\n    ao('-P', '--password', dest='password', action='store_true')",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "get_option_parser",
        "kind": 2,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "def get_option_parser():\n    parser = OptionParser(usage='usage: %prog [options] database_name')\n    ao = parser.add_option\n    ao('-H', '--host', dest='host')\n    ao('-p', '--port', dest='port', type='int')\n    ao('-u', '--user', dest='user')\n    ao('-P', '--password', dest='password', action='store_true')\n    engines = sorted(DATABASE_MAP)\n    ao('-e', '--engine', dest='engine', choices=engines,\n       help=('Database type, e.g. sqlite, mysql, postgresql or cockroachdb. '",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "get_connect_kwargs",
        "kind": 2,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "def get_connect_kwargs(options):\n    ops = ('host', 'port', 'user', 'schema')\n    kwargs = dict((o, getattr(options, o)) for o in ops if getattr(options, o))\n    if options.password:\n        kwargs['password'] = getpass()\n    return kwargs\nif __name__ == '__main__':\n    raw_argv = sys.argv\n    parser = get_option_parser()\n    options, args = parser.parse_args()",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "HEADER",
        "kind": 5,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "HEADER = \"\"\"from peewee import *%s\ndatabase = %s('%s'%s)\n\"\"\"\nBASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "database",
        "kind": 5,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "database = %s('%s'%s)\n\"\"\"\nBASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "BASE_MODEL",
        "kind": 5,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "BASE_MODEL = \"\"\"\\\nclass BaseModel(Model):\n    class Meta:\n        database = database\n\"\"\"\nUNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "UNKNOWN_FIELD",
        "kind": 5,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "UNKNOWN_FIELD = \"\"\"\\\nclass UnknownField(object):\n    def __init__(self, *_, **__): pass\n\"\"\"\nDATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "DATABASE_ALIASES",
        "kind": 5,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "DATABASE_ALIASES = {\n    CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n    MySQLDatabase: ['mysql', 'mysqldb'],\n    PostgresqlDatabase: ['postgres', 'postgresql'],\n    SqliteDatabase: ['sqlite', 'sqlite3'],\n}\nDATABASE_MAP = dict((value, key)\n                    for key in DATABASE_ALIASES\n                    for value in DATABASE_ALIASES[key])\ndef make_introspector(database_type, database_name, **kwargs):",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "DATABASE_MAP",
        "kind": 5,
        "importPath": "abacus.bin.pwiz",
        "description": "abacus.bin.pwiz",
        "peekOfCode": "DATABASE_MAP = dict((value, key)\n                    for key in DATABASE_ALIASES\n                    for value in DATABASE_ALIASES[key])\ndef make_introspector(database_type, database_name, **kwargs):\n    if database_type not in DATABASE_MAP:\n        err('Unrecognized database, must be one of: %s' %\n            ', '.join(DATABASE_MAP.keys()))\n        sys.exit(1)\n    schema = kwargs.pop('schema', None)\n    DatabaseClass = DATABASE_MAP[database_type]",
        "detail": "abacus.bin.pwiz",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "base = importr('base')\nDBI = importr('DBI')\nRPostgres = importr('RPostgres')\nforecast = importr('forecast')\nstats = importr('stats')\n# Database connection parameters\ndb_host = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\ndb_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "DBI",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "DBI = importr('DBI')\nRPostgres = importr('RPostgres')\nforecast = importr('forecast')\nstats = importr('stats')\n# Database connection parameters\ndb_host = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\ndb_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "RPostgres",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "RPostgres = importr('RPostgres')\nforecast = importr('forecast')\nstats = importr('stats')\n# Database connection parameters\ndb_host = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\ndb_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\ntry:",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "forecast",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "forecast = importr('forecast')\nstats = importr('stats')\n# Database connection parameters\ndb_host = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\ndb_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\ntry:\n    # Connect to the database",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "stats",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "stats = importr('stats')\n# Database connection parameters\ndb_host = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\ndb_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\ntry:\n    # Connect to the database\n    logging.info(\"Connecting to the database...\")",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "db_host",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "db_host = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\ndb_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\ntry:\n    # Connect to the database\n    logging.info(\"Connecting to the database...\")\n    con = DBI.dbConnect(RPostgres.Postgres(),\n                        host=db_host,",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "db_name",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "db_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\ntry:\n    # Connect to the database\n    logging.info(\"Connecting to the database...\")\n    con = DBI.dbConnect(RPostgres.Postgres(),\n                        host=db_host,\n                        dbname=db_name,",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "db_user",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "db_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\ntry:\n    # Connect to the database\n    logging.info(\"Connecting to the database...\")\n    con = DBI.dbConnect(RPostgres.Postgres(),\n                        host=db_host,\n                        dbname=db_name,\n                        user=db_user,",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "db_password",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "db_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\ntry:\n    # Connect to the database\n    logging.info(\"Connecting to the database...\")\n    con = DBI.dbConnect(RPostgres.Postgres(),\n                        host=db_host,\n                        dbname=db_name,\n                        user=db_user,\n                        password=db_password,",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "db_port",
        "kind": 5,
        "importPath": "nxmbers.R.arima_model.R",
        "description": "nxmbers.R.arima_model.R",
        "peekOfCode": "db_port = 5432\ntry:\n    # Connect to the database\n    logging.info(\"Connecting to the database...\")\n    con = DBI.dbConnect(RPostgres.Postgres(),\n                        host=db_host,\n                        dbname=db_name,\n                        user=db_user,\n                        password=db_password,\n                        port=db_port)",
        "detail": "nxmbers.R.arima_model.R",
        "documentation": {}
    },
    {
        "label": "kalman_filter",
        "kind": 2,
        "importPath": "nxmbers.R.kalman_filter.R",
        "description": "nxmbers.R.kalman_filter.R",
        "peekOfCode": "def kalman_filter(data, initial_state, process_noise_variance, measurement_noise_variance):\n    \"\"\"\n    Implements a basic Kalman filter for time series data.\n    Args:\n        data: A 1D numpy array containing the time series data.\n        initial_state: A tuple (x0, P0) representing the initial state estimate and its covariance.\n        process_noise_variance: The variance of the process noise (Q).\n        measurement_noise_variance: The variance of the measurement noise (R).\n    Returns:\n        filtered_state_means: A 1D numpy array containing the filtered state estimates.",
        "detail": "nxmbers.R.kalman_filter.R",
        "documentation": {}
    },
    {
        "label": "initial_state",
        "kind": 5,
        "importPath": "nxmbers.R.kalman_filter.R",
        "description": "nxmbers.R.kalman_filter.R",
        "peekOfCode": "initial_state = (pdf['close_alpha'].iloc[0], 1.0)  # Initial state estimate and covariance\nprocess_noise_variance = 0.1  # Adjust based on your understanding of the process\nmeasurement_noise_variance = 1.0  # Adjust based on your understanding of the measurement noise\nfiltered_state_means, filtered_state_covariances = kalman_filter(\n    pdf['close_alpha'].values, initial_state, process_noise_variance, measurement_noise_variance\n)\n# Plot the filtered results\nlogging.info(\"Plotting Kalman filtered results...\")\nplt.figure(figsize=(12, 6))\nplt.plot(pdf['date'], pdf['close_alpha'], label='Actual')",
        "detail": "nxmbers.R.kalman_filter.R",
        "documentation": {}
    },
    {
        "label": "process_noise_variance",
        "kind": 5,
        "importPath": "nxmbers.R.kalman_filter.R",
        "description": "nxmbers.R.kalman_filter.R",
        "peekOfCode": "process_noise_variance = 0.1  # Adjust based on your understanding of the process\nmeasurement_noise_variance = 1.0  # Adjust based on your understanding of the measurement noise\nfiltered_state_means, filtered_state_covariances = kalman_filter(\n    pdf['close_alpha'].values, initial_state, process_noise_variance, measurement_noise_variance\n)\n# Plot the filtered results\nlogging.info(\"Plotting Kalman filtered results...\")\nplt.figure(figsize=(12, 6))\nplt.plot(pdf['date'], pdf['close_alpha'], label='Actual')\nplt.plot(pdf['date'], filtered_state_means, label='Kalman Filtered', color='green')",
        "detail": "nxmbers.R.kalman_filter.R",
        "documentation": {}
    },
    {
        "label": "measurement_noise_variance",
        "kind": 5,
        "importPath": "nxmbers.R.kalman_filter.R",
        "description": "nxmbers.R.kalman_filter.R",
        "peekOfCode": "measurement_noise_variance = 1.0  # Adjust based on your understanding of the measurement noise\nfiltered_state_means, filtered_state_covariances = kalman_filter(\n    pdf['close_alpha'].values, initial_state, process_noise_variance, measurement_noise_variance\n)\n# Plot the filtered results\nlogging.info(\"Plotting Kalman filtered results...\")\nplt.figure(figsize=(12, 6))\nplt.plot(pdf['date'], pdf['close_alpha'], label='Actual')\nplt.plot(pdf['date'], filtered_state_means, label='Kalman Filtered', color='green')\nplt.title('Kalman Filter Results')",
        "detail": "nxmbers.R.kalman_filter.R",
        "documentation": {}
    },
    {
        "label": "clean_data",
        "kind": 2,
        "importPath": "nxmbers.data_cleaning.data_cleaner",
        "description": "nxmbers.data_cleaning.data_cleaner",
        "peekOfCode": "def clean_data():\n    # Define the input path\n    input_file_path = get_data_path(__file__, 'combined_data.csv')\n    # Generate the timestamp\n    timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n    # Define the directory and the file name\n    output_dir = os.path.join(os.getcwd(), '..', 'nxmbers', 'data', 'cleaned')  \n    output_file_name = f'cleaned_data-{timestamp}.csv'\n    output_file_path = os.path.join(output_dir, output_file_name)\n    # Load the combined market data",
        "detail": "nxmbers.data_cleaning.data_cleaner",
        "documentation": {}
    },
    {
        "label": "get_project_path",
        "kind": 2,
        "importPath": "nxmbers.data_cleaning.path_utility",
        "description": "nxmbers.data_cleaning.path_utility",
        "peekOfCode": "def get_project_path(file_path):\n    \"\"\"\n    Get the project path based on the current file's location.\n    :param file_path: The __file__ variable of the current script\n    :return: Path object pointing to the project root (nxmbers folder)\n    \"\"\"\n    current_file = Path(file_path).resolve()\n    project_root = current_file.parent\n    while project_root.name != 'nxmbers':\n        project_root = project_root.parent",
        "detail": "nxmbers.data_cleaning.path_utility",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "kind": 2,
        "importPath": "nxmbers.data_cleaning.path_utility",
        "description": "nxmbers.data_cleaning.path_utility",
        "peekOfCode": "def get_data_path(file_path, filename):\n    \"\"\"\n    Get the full path for a data file within the project.\n    :param file_path: The __file__ variable of the current script\n    :param filename: Name of the file to be saved/loaded\n    :return: Full path to the data file\n    \"\"\"\n    project_root = get_project_path(file_path)\n    data_dir = project_root / 'nxmbers' / 'data'\n    data_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "nxmbers.data_cleaning.path_utility",
        "documentation": {}
    },
    {
        "label": "combine_data",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.data_combiner",
        "description": "nxmbers.data_ingestion.data_combiner",
        "peekOfCode": "def combine_data(yahoo_data, alpha_data):\n    \"\"\"\n    Combine Yahoo Finance and Alpha Vantage data.\n    \"\"\"\n    # Reset index for all dataframes\n    yahoo_data = yahoo_data.reset_index()\n    alpha_data = alpha_data.reset_index()\n    # Ensure consistent date column naming\n    yahoo_data = yahoo_data.rename(columns={'Date': 'date'})\n    alpha_data = alpha_data.rename(columns={'date': 'date'})",
        "detail": "nxmbers.data_ingestion.data_combiner",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.data_combiner",
        "description": "nxmbers.data_ingestion.data_combiner",
        "peekOfCode": "def main(ticker):\n    yahoo_csv_path = get_data_path(__file__, f'{ticker}_yahoo_data.csv')\n    alpha_csv_path = get_data_path(__file__, f'{ticker}_alpha_data.csv')\n    yahoo_data = pd.read_csv(yahoo_csv_path, parse_dates=['date'])\n    alpha_data = pd.read_csv(alpha_csv_path, parse_dates=['date'])\n    combined_data = combine_data(yahoo_data, alpha_data)\n    combined_csv_path = get_data_path(__file__, f'{ticker}_combined_data.csv')\n    combined_data.to_csv(combined_csv_path, index=False)\n    print(f\"Data combination complete for {ticker}.\")\n    print(f\"Combined data saved to '{combined_csv_path}'\")",
        "detail": "nxmbers.data_ingestion.data_combiner",
        "documentation": {}
    },
    {
        "label": "fetch_beam_data",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.data_fetcher",
        "description": "nxmbers.data_ingestion.data_fetcher",
        "peekOfCode": "def fetch_beam_data(ticker, start_date, end_date, interval, api_key):\n    beam_url = 'https://api.beamapi.com/data/fundamentals/us/sec/form_4/v1'\n    transport = RequestsHTTPTransport(\n        url=beam_url,\n        headers={'Authorization': f'Bearer {api_key}'},\n        use_json=True,\n    )\n    try:\n        client = Client(transport=transport, fetch_schema_from_transport=True)\n        query = gql('''",
        "detail": "nxmbers.data_ingestion.data_fetcher",
        "documentation": {}
    },
    {
        "label": "fetch_alpha_vantage_data",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.data_fetcher",
        "description": "nxmbers.data_ingestion.data_fetcher",
        "peekOfCode": "def fetch_alpha_vantage_data(ticker, start_date, end_date, interval):\n    try:\n        ts = TimeSeries(key=config.ALPHA_VANTAGE_API_KEY)\n        data, _ = ts.get_daily(symbol=ticker, outputsize='full')\n        df = pd.DataFrame(data).T\n        df.index = pd.to_datetime(df.index)\n        df = df[(df.index >= start_date) & (df.index <= end_date)]\n        df.reset_index(inplace=True)\n        df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n        df['adj_close'] = df['close']",
        "detail": "nxmbers.data_ingestion.data_fetcher",
        "documentation": {}
    },
    {
        "label": "save_data",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.data_fetcher",
        "description": "nxmbers.data_ingestion.data_fetcher",
        "peekOfCode": "def save_data(data, ticker, source):\n    if data is not None and not data.empty:\n        output_dir = get_data_path(__file__, 'csv')\n        os.makedirs(output_dir, exist_ok=True)\n        output_file = os.path.join(output_dir, f'{ticker}_{source}_data.csv')\n        data.to_csv(output_file, index=False)\n        logger.info(f\"{source.capitalize()} data saved to {output_file}\")\n    else:\n        logger.warning(f\"No data to save for {ticker} from {source}\")\ndef main(ticker, start_date, end_date, interval, api_sources, beam_api_key):",
        "detail": "nxmbers.data_ingestion.data_fetcher",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.data_fetcher",
        "description": "nxmbers.data_ingestion.data_fetcher",
        "peekOfCode": "def main(ticker, start_date, end_date, interval, api_sources, beam_api_key):\n    data_fetched = False\n    for source in api_sources:\n        if source == 'beam':\n            beam_data = fetch_beam_data(ticker, start_date, end_date, interval, beam_api_key)\n            if beam_data is not None:\n                save_data(beam_data, ticker, 'beam')\n                data_fetched = True\n            else:\n                logger.warning(\"Falling back to Alpha Vantage due to Beam API failure\")",
        "detail": "nxmbers.data_ingestion.data_fetcher",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "nxmbers.data_ingestion.data_fetcher",
        "description": "nxmbers.data_ingestion.data_fetcher",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef fetch_beam_data(ticker, start_date, end_date, interval, api_key):\n    beam_url = 'https://api.beamapi.com/data/fundamentals/us/sec/form_4/v1'\n    transport = RequestsHTTPTransport(\n        url=beam_url,\n        headers={'Authorization': f'Bearer {api_key}'},\n        use_json=True,\n    )\n    try:\n        client = Client(transport=transport, fetch_schema_from_transport=True)",
        "detail": "nxmbers.data_ingestion.data_fetcher",
        "documentation": {}
    },
    {
        "label": "get_project_path",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.path_utility",
        "description": "nxmbers.data_ingestion.path_utility",
        "peekOfCode": "def get_project_path(file_path):\n    \"\"\"\n    Get the project path based on the current file's location.\n    :param file_path: The __file__ variable of the current script\n    :return: Path object pointing to the project root (nxmbers folder)\n    \"\"\"\n    current_file = Path(file_path).resolve()\n    project_root = current_file.parent\n    while project_root.name != 'nxmbers':\n        project_root = project_root.parent",
        "detail": "nxmbers.data_ingestion.path_utility",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "kind": 2,
        "importPath": "nxmbers.data_ingestion.path_utility",
        "description": "nxmbers.data_ingestion.path_utility",
        "peekOfCode": "def get_data_path(file_path, filename):\n    \"\"\"\n    Get the full path for a data file within the project.\n    :param file_path: The __file__ variable of the current script\n    :param filename: Name of the file to be saved/loaded\n    :return: Full path to the data file\n    \"\"\"\n    project_root = get_project_path(file_path)\n    data_dir = project_root / 'nxmbers' / 'data'\n    data_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "nxmbers.data_ingestion.path_utility",
        "documentation": {}
    },
    {
        "label": "get_project_path",
        "kind": 2,
        "importPath": "nxmbers.data_storage.path_utility",
        "description": "nxmbers.data_storage.path_utility",
        "peekOfCode": "def get_project_path(file_path):\n    \"\"\"\n    Get the project path based on the current file's location.\n    :param file_path: The __file__ variable of the current script\n    :return: Path object pointing to the project root (nxmbers folder)\n    \"\"\"\n    current_file = Path(file_path).resolve()\n    project_root = current_file.parent\n    while project_root.name != 'nxmbers':\n        project_root = project_root.parent",
        "detail": "nxmbers.data_storage.path_utility",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "kind": 2,
        "importPath": "nxmbers.data_storage.path_utility",
        "description": "nxmbers.data_storage.path_utility",
        "peekOfCode": "def get_data_path(file_path, filename):\n    \"\"\"\n    Get the full path for a data file within the project.\n    :param file_path: The __file__ variable of the current script\n    :param filename: Name of the file to be saved/loaded\n    :return: Full path to the data file\n    \"\"\"\n    project_root = get_project_path(file_path)\n    data_dir = project_root / 'nxmbers' / 'data'\n    data_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "nxmbers.data_storage.path_utility",
        "documentation": {}
    },
    {
        "label": "create_table_name",
        "kind": 2,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "def create_table_name():\n    \"\"\"Create a table name with current date.\"\"\"\n    return f\"market_data_{datetime.now().strftime('%Y_%m_%d_%H%M%S')}\"\ndef get_column_types(df):\n    \"\"\"Map pandas dtypes to PostgreSQL column types.\"\"\"\n    type_mapping = {\n        'int64': 'INTEGER',\n        'float64': 'FLOAT',\n        'object': 'TEXT',\n        'datetime64[ns]': 'TIMESTAMP'",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "get_column_types",
        "kind": 2,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "def get_column_types(df):\n    \"\"\"Map pandas dtypes to PostgreSQL column types.\"\"\"\n    type_mapping = {\n        'int64': 'INTEGER',\n        'float64': 'FLOAT',\n        'object': 'TEXT',\n        'datetime64[ns]': 'TIMESTAMP'\n    }\n    return {col: type_mapping.get(str(df[col].dtype), 'TEXT') for col in df.columns}\ndef create_table(conn, cursor, table_name, column_types):",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "create_table",
        "kind": 2,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "def create_table(conn, cursor, table_name, column_types):\n    \"\"\"Create a new table in the database.\"\"\"\n    columns = [\n        sql.SQL(\"{} {}\").format(\n            sql.Identifier(col),\n            sql.SQL(col_type)\n        ) for col, col_type in column_types.items()\n    ]\n    create_table_query = sql.SQL(\"CREATE TABLE IF NOT EXISTS {} ({})\").format(\n        sql.Identifier(table_name),",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "insert_data",
        "kind": 2,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "def insert_data(conn, cursor, table_name, df):\n    \"\"\"Insert data into the table.\"\"\"\n    columns = list(df.columns)\n    values = [tuple(x) for x in df.to_numpy()]\n    insert_query = sql.SQL(\"INSERT INTO {} ({}) VALUES ({})\").format(\n        sql.Identifier(table_name),\n        sql.SQL(', ').join(map(sql.Identifier, columns)),\n        sql.SQL(', ').join(sql.Placeholder() * len(columns))\n    )\n    for value in tqdm(values, desc=\"Inserting data\"):",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "upload_to_rds",
        "kind": 2,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "def upload_to_rds(file_path):\n    # Read the CSV file\n    df = pd.read_csv(file_path)\n    # Ensure 'date' column is datetime\n    df['date'] = pd.to_datetime(df['date'])\n    # Connect to the database\n    conn = psycopg2.connect(\n        host=DB_HOST,\n        database=DB_NAME,\n        user=DB_USER,",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "DB_HOST",
        "kind": 5,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "DB_HOST = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\nDB_NAME = \"nxmbers\"\nDB_USER = \"mxchinist\"\nDB_PASS = \"foJzyn-miwhor-bavpo4\"\nDB_PORT = \"5432\"\ndef create_table_name():\n    \"\"\"Create a table name with current date.\"\"\"\n    return f\"market_data_{datetime.now().strftime('%Y_%m_%d_%H%M%S')}\"\ndef get_column_types(df):\n    \"\"\"Map pandas dtypes to PostgreSQL column types.\"\"\"",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "DB_NAME",
        "kind": 5,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "DB_NAME = \"nxmbers\"\nDB_USER = \"mxchinist\"\nDB_PASS = \"foJzyn-miwhor-bavpo4\"\nDB_PORT = \"5432\"\ndef create_table_name():\n    \"\"\"Create a table name with current date.\"\"\"\n    return f\"market_data_{datetime.now().strftime('%Y_%m_%d_%H%M%S')}\"\ndef get_column_types(df):\n    \"\"\"Map pandas dtypes to PostgreSQL column types.\"\"\"\n    type_mapping = {",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "DB_USER",
        "kind": 5,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "DB_USER = \"mxchinist\"\nDB_PASS = \"foJzyn-miwhor-bavpo4\"\nDB_PORT = \"5432\"\ndef create_table_name():\n    \"\"\"Create a table name with current date.\"\"\"\n    return f\"market_data_{datetime.now().strftime('%Y_%m_%d_%H%M%S')}\"\ndef get_column_types(df):\n    \"\"\"Map pandas dtypes to PostgreSQL column types.\"\"\"\n    type_mapping = {\n        'int64': 'INTEGER',",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "DB_PASS",
        "kind": 5,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "DB_PASS = \"foJzyn-miwhor-bavpo4\"\nDB_PORT = \"5432\"\ndef create_table_name():\n    \"\"\"Create a table name with current date.\"\"\"\n    return f\"market_data_{datetime.now().strftime('%Y_%m_%d_%H%M%S')}\"\ndef get_column_types(df):\n    \"\"\"Map pandas dtypes to PostgreSQL column types.\"\"\"\n    type_mapping = {\n        'int64': 'INTEGER',\n        'float64': 'FLOAT',",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "DB_PORT",
        "kind": 5,
        "importPath": "nxmbers.data_storage.rds_uploader",
        "description": "nxmbers.data_storage.rds_uploader",
        "peekOfCode": "DB_PORT = \"5432\"\ndef create_table_name():\n    \"\"\"Create a table name with current date.\"\"\"\n    return f\"market_data_{datetime.now().strftime('%Y_%m_%d_%H%M%S')}\"\ndef get_column_types(df):\n    \"\"\"Map pandas dtypes to PostgreSQL column types.\"\"\"\n    type_mapping = {\n        'int64': 'INTEGER',\n        'float64': 'FLOAT',\n        'object': 'TEXT',",
        "detail": "nxmbers.data_storage.rds_uploader",
        "documentation": {}
    },
    {
        "label": "update_config",
        "kind": 2,
        "importPath": "nxmbers.app",
        "description": "nxmbers.app",
        "peekOfCode": "def update_config():\n    data = request.json\n    config.USER_TICKER = data.get('ticker', config.DEFAULT_TICKER)\n    config.USER_START_DATE = data.get('startDate', config.DEFAULT_START_DATE)\n    config.USER_END_DATE = data.get('endDate', config.DEFAULT_END_DATE)\n    config.USER_INTERVAL = data.get('interval', config.DEFAULT_INTERVAL)\n    config.USER_API_SOURCES = data.get('apiSources', config.DEFAULT_API_SOURCES)\n    try:\n        result = fetch_data(\n            ticker=config.USER_TICKER,",
        "detail": "nxmbers.app",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "nxmbers.app",
        "description": "nxmbers.app",
        "peekOfCode": "def index():\n    return render_template('index.html', \n                           default_ticker=config.DEFAULT_TICKER,\n                           default_start_date=config.DEFAULT_START_DATE,\n                           default_end_date=config.DEFAULT_END_DATE,\n                           default_interval=config.DEFAULT_INTERVAL,\n                           default_api_sources=config.DEFAULT_API_SOURCES)\nif __name__ == '__main__':\n    app.run(debug=True)",
        "detail": "nxmbers.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "nxmbers.app",
        "description": "nxmbers.app",
        "peekOfCode": "app = Flask(__name__)\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n@app.route('/api/update-config', methods=['POST'])\ndef update_config():\n    data = request.json\n    config.USER_TICKER = data.get('ticker', config.DEFAULT_TICKER)\n    config.USER_START_DATE = data.get('startDate', config.DEFAULT_START_DATE)\n    config.USER_END_DATE = data.get('endDate', config.DEFAULT_END_DATE)\n    config.USER_INTERVAL = data.get('interval', config.DEFAULT_INTERVAL)",
        "detail": "nxmbers.app",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "nxmbers.app",
        "description": "nxmbers.app",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@app.route('/api/update-config', methods=['POST'])\ndef update_config():\n    data = request.json\n    config.USER_TICKER = data.get('ticker', config.DEFAULT_TICKER)\n    config.USER_START_DATE = data.get('startDate', config.DEFAULT_START_DATE)\n    config.USER_END_DATE = data.get('endDate', config.DEFAULT_END_DATE)\n    config.USER_INTERVAL = data.get('interval', config.DEFAULT_INTERVAL)\n    config.USER_API_SOURCES = data.get('apiSources', config.DEFAULT_API_SOURCES)\n    try:",
        "detail": "nxmbers.app",
        "documentation": {}
    },
    {
        "label": "db_host",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "db_host = \"numbermxchine.cxwoaq8ccu34.eu-west-2.rds.amazonaws.com\"\ndb_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\nforecast_horizon = 12\n# ... other variables\n# config.py\nALPHA_VANTAGE_API_KEY = \"KXUK213E0W7JLEQV\"\nBEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "db_name",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "db_name = \"nxmbers\"\ndb_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\nforecast_horizon = 12\n# ... other variables\n# config.py\nALPHA_VANTAGE_API_KEY = \"KXUK213E0W7JLEQV\"\nBEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"\nDEFAULT_TICKER = 'AAPL'",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "db_user",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "db_user = \"mxchinist\"\ndb_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\nforecast_horizon = 12\n# ... other variables\n# config.py\nALPHA_VANTAGE_API_KEY = \"KXUK213E0W7JLEQV\"\nBEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"\nDEFAULT_TICKER = 'AAPL'\nDEFAULT_START_DATE = '2000-01-01'",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "db_password",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "db_password = \"foJzyn-miwhor-bavpo4\"\ndb_port = 5432\nforecast_horizon = 12\n# ... other variables\n# config.py\nALPHA_VANTAGE_API_KEY = \"KXUK213E0W7JLEQV\"\nBEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"\nDEFAULT_TICKER = 'AAPL'\nDEFAULT_START_DATE = '2000-01-01'\nDEFAULT_END_DATE = '2024-08-01'",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "db_port",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "db_port = 5432\nforecast_horizon = 12\n# ... other variables\n# config.py\nALPHA_VANTAGE_API_KEY = \"KXUK213E0W7JLEQV\"\nBEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"\nDEFAULT_TICKER = 'AAPL'\nDEFAULT_START_DATE = '2000-01-01'\nDEFAULT_END_DATE = '2024-08-01'\nDEFAULT_INTERVAL = '1day'",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "forecast_horizon",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "forecast_horizon = 12\n# ... other variables\n# config.py\nALPHA_VANTAGE_API_KEY = \"KXUK213E0W7JLEQV\"\nBEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"\nDEFAULT_TICKER = 'AAPL'\nDEFAULT_START_DATE = '2000-01-01'\nDEFAULT_END_DATE = '2024-08-01'\nDEFAULT_INTERVAL = '1day'\nDEFAULT_API_SOURCES = ['beam', 'alpha']",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "ALPHA_VANTAGE_API_KEY",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "ALPHA_VANTAGE_API_KEY = \"KXUK213E0W7JLEQV\"\nBEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"\nDEFAULT_TICKER = 'AAPL'\nDEFAULT_START_DATE = '2000-01-01'\nDEFAULT_END_DATE = '2024-08-01'\nDEFAULT_INTERVAL = '1day'\nDEFAULT_API_SOURCES = ['beam', 'alpha']\n# User input values (to be updated by the frontend)\nUSER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "BEAM_API_KEY",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "BEAM_API_KEY = \"NmJkNzkxNGQtYzUwMy00YjAzLTkyMzYtODUxMmJlYWJmY2M1\"\nDEFAULT_TICKER = 'AAPL'\nDEFAULT_START_DATE = '2000-01-01'\nDEFAULT_END_DATE = '2024-08-01'\nDEFAULT_INTERVAL = '1day'\nDEFAULT_API_SOURCES = ['beam', 'alpha']\n# User input values (to be updated by the frontend)\nUSER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_TICKER",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "DEFAULT_TICKER = 'AAPL'\nDEFAULT_START_DATE = '2000-01-01'\nDEFAULT_END_DATE = '2024-08-01'\nDEFAULT_INTERVAL = '1day'\nDEFAULT_API_SOURCES = ['beam', 'alpha']\n# User input values (to be updated by the frontend)\nUSER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_START_DATE",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "DEFAULT_START_DATE = '2000-01-01'\nDEFAULT_END_DATE = '2024-08-01'\nDEFAULT_INTERVAL = '1day'\nDEFAULT_API_SOURCES = ['beam', 'alpha']\n# User input values (to be updated by the frontend)\nUSER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_END_DATE",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "DEFAULT_END_DATE = '2024-08-01'\nDEFAULT_INTERVAL = '1day'\nDEFAULT_API_SOURCES = ['beam', 'alpha']\n# User input values (to be updated by the frontend)\nUSER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_INTERVAL",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "DEFAULT_INTERVAL = '1day'\nDEFAULT_API_SOURCES = ['beam', 'alpha']\n# User input values (to be updated by the frontend)\nUSER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "DEFAULT_API_SOURCES",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "DEFAULT_API_SOURCES = ['beam', 'alpha']\n# User input values (to be updated by the frontend)\nUSER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "USER_TICKER",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "USER_TICKER = DEFAULT_TICKER\nUSER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "USER_START_DATE",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "USER_START_DATE = DEFAULT_START_DATE\nUSER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "USER_END_DATE",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "USER_END_DATE = DEFAULT_END_DATE\nUSER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "USER_INTERVAL",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "USER_INTERVAL = DEFAULT_INTERVAL\nUSER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "USER_API_SOURCES",
        "kind": 5,
        "importPath": "nxmbers.config",
        "description": "nxmbers.config",
        "peekOfCode": "USER_API_SOURCES = DEFAULT_API_SOURCES",
        "detail": "nxmbers.config",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "nxmbers.main",
        "description": "nxmbers.main",
        "peekOfCode": "def main():\n    # Fetch data\n    fetch_data(\n        ticker=config.USER_TICKER,\n        start_date=config.USER_START_DATE,\n        end_date=config.USER_END_DATE,\n        interval=config.USER_INTERVAL,\n        api_sources=config.USER_API_SOURCES,\n        beam_api_key=config.BEAM_API_KEY\n    )",
        "detail": "nxmbers.main",
        "documentation": {}
    },
    {
        "label": "get_project_path",
        "kind": 2,
        "importPath": "nxmbers.path_utility",
        "description": "nxmbers.path_utility",
        "peekOfCode": "def get_project_path(file_path):\n    \"\"\"\n    Get the project path based on the current file's location.\n    :param file_path: The __file__ variable of the current script\n    :return: Path object pointing to the project root (nxmbers folder)\n    \"\"\"\n    current_file = Path(file_path).resolve()\n    project_root = current_file.parent\n    while project_root.name != 'nxmbers':\n        project_root = project_root.parent",
        "detail": "nxmbers.path_utility",
        "documentation": {}
    },
    {
        "label": "get_data_path",
        "kind": 2,
        "importPath": "nxmbers.path_utility",
        "description": "nxmbers.path_utility",
        "peekOfCode": "def get_data_path(file_path, filename):\n    \"\"\"\n    Get the full path for a data file within the project.\n    :param file_path: The __file__ variable of the current script\n    :param filename: Name of the file to be saved/loaded\n    :return: Full path to the data file\n    \"\"\"\n    project_root = get_project_path(file_path)\n    data_dir = project_root / 'nxmbers' / 'data'\n    data_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "nxmbers.path_utility",
        "documentation": {}
    },
    {
        "label": "print_directory_tree",
        "kind": 2,
        "importPath": "nxmbers.tree",
        "description": "nxmbers.tree",
        "peekOfCode": "def print_directory_tree(path, prefix=\"\"):\n    \"\"\"Recursively prints a directory tree, ignoring hidden files.\"\"\"\n    entries = [entry for entry in os.listdir(path) if not entry.startswith('.')]\n    entries.sort() \n    num_entries = len(entries)\n    for index, entry in enumerate(entries):\n        entry_path = os.path.join(path, entry)\n        if os.path.isdir(entry_path):\n            # Directory\n            connector = \" \" if index == num_entries - 1 else \" \"",
        "detail": "nxmbers.tree",
        "documentation": {}
    },
    {
        "label": "start_path",
        "kind": 5,
        "importPath": "nxmbers.tree",
        "description": "nxmbers.tree",
        "peekOfCode": "start_path = \".\"\nprint_directory_tree(start_path)",
        "detail": "nxmbers.tree",
        "documentation": {}
    }
]